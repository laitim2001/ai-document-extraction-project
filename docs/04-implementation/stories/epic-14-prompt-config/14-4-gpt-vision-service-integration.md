# Story 14-4: GPT Vision æœå‹™æ•´åˆ

> **Epic**: Epic 14 - Prompt é…ç½®èˆ‡å‹•æ…‹ç”Ÿæˆ
> **Story Points**: 8
> **Priority**: High
> **Status**: Backlog

---

## ğŸ“‹ User Story

**As a** ç³»çµ±
**I want** GPT Vision æœå‹™èƒ½ä½¿ç”¨å‹•æ…‹ç”Ÿæˆçš„ Prompt
**So that** AI è™•ç†èƒ½æ ¹æ“šå…¬å¸/æ ¼å¼ç‰¹å®šé…ç½®ç”¢ç”Ÿæ›´æº–ç¢ºçš„çµæœ

---

## ğŸ¯ Acceptance Criteria

### AC 14-4-1: Prompt å¼•æ“æ•´åˆ
- [ ] GPT Vision æœå‹™åœ¨è™•ç†å‰èª¿ç”¨ PromptEngine ç²å–å‹•æ…‹ Prompt
- [ ] æ”¯æ´å››ç¨® Prompt é¡å‹çš„å‹•æ…‹è¼‰å…¥
- [ ] åœ¨ç¼ºå°‘ç‰¹å®šé…ç½®æ™‚å„ªé›…é™ç´šåˆ°å…¨åŸŸ Prompt
- [ ] è¨˜éŒ„ä½¿ç”¨çš„ Prompt é…ç½®ç”¨æ–¼è¿½è¹¤

### AC 14-4-2: ä¸Šä¸‹æ–‡è®Šæ•¸æ³¨å…¥
- [ ] è‡ªå‹•æ³¨å…¥è™•ç†ä¸Šä¸‹æ–‡ï¼ˆå…¬å¸åç¨±ã€æ ¼å¼åç¨±ç­‰ï¼‰
- [ ] æ”¯æ´å¾æå–çµæœæ³¨å…¥å‹•æ…‹è®Šæ•¸
- [ ] è™•ç†è®Šæ•¸æ›¿æ›å¤±æ•—çš„æƒ…æ³
- [ ] æä¾›è®Šæ•¸æ›¿æ›çš„æ—¥èªŒè¨˜éŒ„

### AC 14-4-3: å¤šéšæ®µè™•ç†æ”¯æ´
- [ ] ç™¼è¡Œè€…è­˜åˆ¥éšæ®µä½¿ç”¨ ISSUER_IDENTIFICATION Prompt
- [ ] è¡“èªåˆ†é¡éšæ®µä½¿ç”¨ TERM_CLASSIFICATION Prompt
- [ ] æ¬„ä½æå–éšæ®µä½¿ç”¨ FIELD_EXTRACTION Prompt
- [ ] é©—è­‰éšæ®µä½¿ç”¨ VALIDATION Prompt

### AC 14-4-4: æ•ˆèƒ½èˆ‡ç›£æ§
- [ ] Prompt è§£ææ™‚é–“ < 50ms
- [ ] è¨˜éŒ„ Prompt ä½¿ç”¨çµ±è¨ˆ
- [ ] æ”¯æ´ Prompt æ•ˆæœè¿½è¹¤ï¼ˆèˆ‡è™•ç†æº–ç¢ºç‡é—œè¯ï¼‰
- [ ] æä¾› Prompt ä½¿ç”¨å ±å‘Š

---

## ğŸ—ï¸ Technical Design

### æœå‹™æ¶æ§‹

```
src/services/gpt-vision/
â”œâ”€â”€ gpt-vision.service.ts         # ä¸»æœå‹™ï¼ˆä¿®æ”¹ï¼‰
â”œâ”€â”€ prompt-integration.service.ts  # Prompt æ•´åˆæœå‹™ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ vision-result-processor.ts     # çµæœè™•ç†å™¨
â”œâ”€â”€ types.ts                       # é¡å‹å®šç¾©
â””â”€â”€ index.ts                       # æ¨¡çµ„å°å‡º
```

### é¡å‹å®šç¾©

```typescript
// src/services/gpt-vision/types.ts

import { PromptType, ResolvedPrompt } from '@/services/prompt-engine/types';

/**
 * è™•ç†éšæ®µ
 */
export enum ProcessingStage {
  ISSUER_IDENTIFICATION = 'ISSUER_IDENTIFICATION',
  TERM_CLASSIFICATION = 'TERM_CLASSIFICATION',
  FIELD_EXTRACTION = 'FIELD_EXTRACTION',
  VALIDATION = 'VALIDATION',
}

/**
 * éšæ®µåˆ° Prompt é¡å‹çš„æ˜ å°„
 */
export const STAGE_TO_PROMPT_TYPE: Record<ProcessingStage, PromptType> = {
  [ProcessingStage.ISSUER_IDENTIFICATION]: PromptType.ISSUER_IDENTIFICATION,
  [ProcessingStage.TERM_CLASSIFICATION]: PromptType.TERM_CLASSIFICATION,
  [ProcessingStage.FIELD_EXTRACTION]: PromptType.FIELD_EXTRACTION,
  [ProcessingStage.VALIDATION]: PromptType.VALIDATION,
};

/**
 * GPT Vision è™•ç†ä¸Šä¸‹æ–‡
 */
export interface VisionProcessingContext {
  fileId: string;
  companyId?: string;
  documentFormatId?: string;
  companyName?: string;
  formatName?: string;
  documentType?: string;
  previousResults?: Record<string, unknown>;
}

/**
 * Prompt ä½¿ç”¨è¨˜éŒ„
 */
export interface PromptUsageRecord {
  fileId: string;
  stage: ProcessingStage;
  promptType: PromptType;
  resolvedPrompt: ResolvedPrompt;
  executionTimeMs: number;
  success: boolean;
  resultConfidence?: number;
}

/**
 * GPT Vision è«‹æ±‚
 */
export interface VisionRequest {
  imageBase64: string;
  stage: ProcessingStage;
  context: VisionProcessingContext;
  options?: {
    maxTokens?: number;
    temperature?: number;
  };
}

/**
 * GPT Vision éŸ¿æ‡‰
 */
export interface VisionResponse {
  stage: ProcessingStage;
  result: Record<string, unknown>;
  confidence: number;
  promptUsed: {
    configIds: string[];
    promptType: PromptType;
  };
  processingTimeMs: number;
}
```

### Prompt æ•´åˆæœå‹™

```typescript
// src/services/gpt-vision/prompt-integration.service.ts

/**
 * @fileoverview GPT Vision Prompt æ•´åˆæœå‹™
 * @description
 *   è² è²¬ç‚º GPT Vision å„è™•ç†éšæ®µç²å–å‹•æ…‹ Prompt
 *   æ•´åˆ PromptEngine å’Œè™•ç†ä¸Šä¸‹æ–‡
 *
 * @module src/services/gpt-vision/prompt-integration
 * @since Epic 14 - Story 14-4
 */

import { promptEngine, PromptType, ResolvedPrompt } from '@/services/prompt-engine';
import {
  ProcessingStage,
  STAGE_TO_PROMPT_TYPE,
  VisionProcessingContext,
  PromptUsageRecord
} from './types';

export class PromptIntegrationService {
  private usageRecords: PromptUsageRecord[] = [];

  /**
   * ç‚ºè™•ç†éšæ®µç²å– Prompt
   */
  async getPromptForStage(
    stage: ProcessingStage,
    context: VisionProcessingContext
  ): Promise<{
    prompt: string;
    resolvedPrompt: ResolvedPrompt;
  }> {
    const startTime = Date.now();
    const promptType = STAGE_TO_PROMPT_TYPE[stage];

    try {
      // å»ºç«‹ä¸Šä¸‹æ–‡è®Šæ•¸
      const variables = this.buildContextVariables(context);

      // è§£æ Prompt
      const resolvedPrompt = await promptEngine.resolvePrompt(
        promptType,
        {
          companyId: context.companyId,
          documentFormatId: context.documentFormatId,
          documentType: context.documentType,
          additionalVariables: variables,
        }
      );

      const executionTimeMs = Date.now() - startTime;

      // è¨˜éŒ„ä½¿ç”¨
      this.recordUsage({
        fileId: context.fileId,
        stage,
        promptType,
        resolvedPrompt,
        executionTimeMs,
        success: true,
      });

      return {
        prompt: resolvedPrompt.finalPrompt,
        resolvedPrompt,
      };
    } catch (error) {
      console.error(`[PromptIntegration] Failed to resolve prompt for stage ${stage}:`, error);

      // è¿”å›é è¨­ Prompt
      const fallbackPrompt = this.getFallbackPrompt(stage);
      return {
        prompt: fallbackPrompt,
        resolvedPrompt: {
          promptType,
          finalPrompt: fallbackPrompt,
          usedConfigs: [],
          variables: {},
          resolvedAt: new Date(),
        },
      };
    }
  }

  /**
   * ç‚ºå¤šå€‹éšæ®µæ‰¹æ¬¡ç²å– Prompt
   */
  async getPromptsForStages(
    stages: ProcessingStage[],
    context: VisionProcessingContext
  ): Promise<Map<ProcessingStage, { prompt: string; resolvedPrompt: ResolvedPrompt }>> {
    const results = new Map<ProcessingStage, { prompt: string; resolvedPrompt: ResolvedPrompt }>();

    await Promise.all(
      stages.map(async (stage) => {
        const result = await this.getPromptForStage(stage, context);
        results.set(stage, result);
      })
    );

    return results;
  }

  /**
   * å»ºç«‹ä¸Šä¸‹æ–‡è®Šæ•¸
   */
  private buildContextVariables(
    context: VisionProcessingContext
  ): Record<string, string> {
    return {
      fileId: context.fileId,
      companyName: context.companyName || 'Unknown Company',
      formatName: context.formatName || 'Unknown Format',
      documentType: context.documentType || 'Invoice',
      hasCompanyContext: context.companyId ? 'true' : 'false',
      hasFormatContext: context.documentFormatId ? 'true' : 'false',
      previousResultsAvailable: context.previousResults ? 'true' : 'false',
    };
  }

  /**
   * ç²å–é™ç´š Prompt
   */
  private getFallbackPrompt(stage: ProcessingStage): string {
    const fallbacks: Record<ProcessingStage, string> = {
      [ProcessingStage.ISSUER_IDENTIFICATION]: `
        Analyze this document image and identify the document issuer.
        Look for company logos, letterheads, and sender information.
        Return a JSON object with: issuerName, confidence, method.
      `,
      [ProcessingStage.TERM_CLASSIFICATION]: `
        Analyze the terms and descriptions in this document.
        Classify each term into standard categories: FREIGHT, HANDLING, DOCUMENTATION, CUSTOMS, INSURANCE, STORAGE, PICKUP_DELIVERY, SURCHARGE, TAX, OTHER.
        Return a JSON array of classified terms.
      `,
      [ProcessingStage.FIELD_EXTRACTION]: `
        Extract invoice data from this document image.
        Include: invoiceNumber, invoiceDate, vendorName, totalAmount, lineItems.
        Return the extracted data as a JSON object.
      `,
      [ProcessingStage.VALIDATION]: `
        Validate the extracted data for consistency and completeness.
        Check for: date format, numeric values, required fields.
        Return validation results with any issues found.
      `,
    };

    return fallbacks[stage].trim();
  }

  /**
   * è¨˜éŒ„ Prompt ä½¿ç”¨
   */
  private recordUsage(record: PromptUsageRecord): void {
    this.usageRecords.push(record);

    // ä¿ç•™æœ€è¿‘ 1000 æ¢è¨˜éŒ„
    if (this.usageRecords.length > 1000) {
      this.usageRecords = this.usageRecords.slice(-1000);
    }
  }

  /**
   * æ›´æ–°ä½¿ç”¨è¨˜éŒ„çš„çµæœä¿¡å¿ƒåº¦
   */
  updateResultConfidence(fileId: string, stage: ProcessingStage, confidence: number): void {
    const record = this.usageRecords.find(
      r => r.fileId === fileId && r.stage === stage
    );
    if (record) {
      record.resultConfidence = confidence;
    }
  }

  /**
   * ç²å–ä½¿ç”¨çµ±è¨ˆ
   */
  getUsageStatistics(): {
    totalCalls: number;
    byStage: Record<ProcessingStage, { count: number; avgTimeMs: number }>;
    avgConfidence: number;
  } {
    const byStage: Record<ProcessingStage, { count: number; totalTime: number; totalConfidence: number }> = {
      [ProcessingStage.ISSUER_IDENTIFICATION]: { count: 0, totalTime: 0, totalConfidence: 0 },
      [ProcessingStage.TERM_CLASSIFICATION]: { count: 0, totalTime: 0, totalConfidence: 0 },
      [ProcessingStage.FIELD_EXTRACTION]: { count: 0, totalTime: 0, totalConfidence: 0 },
      [ProcessingStage.VALIDATION]: { count: 0, totalTime: 0, totalConfidence: 0 },
    };

    let totalConfidence = 0;
    let confidenceCount = 0;

    for (const record of this.usageRecords) {
      byStage[record.stage].count++;
      byStage[record.stage].totalTime += record.executionTimeMs;
      if (record.resultConfidence !== undefined) {
        byStage[record.stage].totalConfidence += record.resultConfidence;
        totalConfidence += record.resultConfidence;
        confidenceCount++;
      }
    }

    const result: Record<ProcessingStage, { count: number; avgTimeMs: number }> = {} as any;
    for (const stage of Object.values(ProcessingStage)) {
      const data = byStage[stage];
      result[stage] = {
        count: data.count,
        avgTimeMs: data.count > 0 ? data.totalTime / data.count : 0,
      };
    }

    return {
      totalCalls: this.usageRecords.length,
      byStage: result,
      avgConfidence: confidenceCount > 0 ? totalConfidence / confidenceCount : 0,
    };
  }
}
```

### GPT Vision æœå‹™ä¿®æ”¹

```typescript
// src/services/gpt-vision/gpt-vision.service.ts

/**
 * @fileoverview GPT Vision æœå‹™
 * @description
 *   æ•´åˆ Azure OpenAI GPT-4 Vision é€²è¡Œæ–‡ä»¶åˆ†æ
 *   ä½¿ç”¨å‹•æ…‹ Prompt é…ç½®æå‡è™•ç†æº–ç¢ºåº¦
 *
 * @module src/services/gpt-vision/gpt-vision
 * @since Epic 0 - Story 0-2
 * @lastModified 2026-01-02 (Epic 14 - Story 14-4)
 */

import { AzureOpenAI } from '@azure/openai';
import { PromptIntegrationService } from './prompt-integration.service';
import {
  ProcessingStage,
  VisionProcessingContext,
  VisionRequest,
  VisionResponse
} from './types';

export class GPTVisionService {
  private client: AzureOpenAI;
  private promptIntegration: PromptIntegrationService;

  constructor() {
    this.client = new AzureOpenAI({
      apiKey: process.env.AZURE_OPENAI_API_KEY,
      endpoint: process.env.AZURE_OPENAI_ENDPOINT,
      apiVersion: '2024-02-15-preview',
    });
    this.promptIntegration = new PromptIntegrationService();
  }

  /**
   * è™•ç†å–®ä¸€éšæ®µ
   */
  async processStage(request: VisionRequest): Promise<VisionResponse> {
    const startTime = Date.now();

    // ç²å–å‹•æ…‹ Prompt
    const { prompt, resolvedPrompt } = await this.promptIntegration.getPromptForStage(
      request.stage,
      request.context
    );

    // å‘¼å« GPT Vision
    const response = await this.client.chat.completions.create({
      model: process.env.AZURE_OPENAI_DEPLOYMENT_NAME || 'gpt-4-vision',
      messages: [
        {
          role: 'system',
          content: prompt,
        },
        {
          role: 'user',
          content: [
            {
              type: 'image_url',
              image_url: {
                url: `data:image/png;base64,${request.imageBase64}`,
              },
            },
          ],
        },
      ],
      max_tokens: request.options?.maxTokens || 4096,
      temperature: request.options?.temperature || 0.1,
    });

    // è§£æçµæœ
    const content = response.choices[0]?.message?.content || '{}';
    const result = this.parseResult(content);
    const confidence = this.calculateConfidence(result, request.stage);

    // æ›´æ–°ä½¿ç”¨è¨˜éŒ„
    this.promptIntegration.updateResultConfidence(
      request.context.fileId,
      request.stage,
      confidence
    );

    return {
      stage: request.stage,
      result,
      confidence,
      promptUsed: {
        configIds: resolvedPrompt.usedConfigs.map(c => c.configId),
        promptType: resolvedPrompt.promptType,
      },
      processingTimeMs: Date.now() - startTime,
    };
  }

  /**
   * åŸ·è¡Œå®Œæ•´è™•ç†æµç¨‹
   */
  async processDocument(
    imageBase64: string,
    context: VisionProcessingContext
  ): Promise<{
    stages: VisionResponse[];
    totalTimeMs: number;
    overallConfidence: number;
  }> {
    const startTime = Date.now();
    const stages: VisionResponse[] = [];

    // éšæ®µ 1: ç™¼è¡Œè€…è­˜åˆ¥
    const issuerResult = await this.processStage({
      imageBase64,
      stage: ProcessingStage.ISSUER_IDENTIFICATION,
      context,
    });
    stages.push(issuerResult);

    // æ›´æ–°ä¸Šä¸‹æ–‡
    const enrichedContext = {
      ...context,
      previousResults: { issuer: issuerResult.result },
    };

    // éšæ®µ 2: æ¬„ä½æå–
    const extractionResult = await this.processStage({
      imageBase64,
      stage: ProcessingStage.FIELD_EXTRACTION,
      context: enrichedContext,
    });
    stages.push(extractionResult);

    // éšæ®µ 3: è¡“èªåˆ†é¡
    const termResult = await this.processStage({
      imageBase64,
      stage: ProcessingStage.TERM_CLASSIFICATION,
      context: {
        ...enrichedContext,
        previousResults: {
          ...enrichedContext.previousResults,
          extraction: extractionResult.result,
        },
      },
    });
    stages.push(termResult);

    // éšæ®µ 4: é©—è­‰
    const validationResult = await this.processStage({
      imageBase64,
      stage: ProcessingStage.VALIDATION,
      context: {
        ...enrichedContext,
        previousResults: {
          ...enrichedContext.previousResults,
          extraction: extractionResult.result,
          terms: termResult.result,
        },
      },
    });
    stages.push(validationResult);

    // è¨ˆç®—æ•´é«”ä¿¡å¿ƒåº¦
    const overallConfidence = this.calculateOverallConfidence(stages);

    return {
      stages,
      totalTimeMs: Date.now() - startTime,
      overallConfidence,
    };
  }

  /**
   * è§£æ GPT å›æ‡‰
   */
  private parseResult(content: string): Record<string, unknown> {
    try {
      // å˜—è©¦æå– JSON
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        return JSON.parse(jsonMatch[0]);
      }
      return { raw: content };
    } catch {
      return { raw: content, parseError: true };
    }
  }

  /**
   * è¨ˆç®—éšæ®µä¿¡å¿ƒåº¦
   */
  private calculateConfidence(
    result: Record<string, unknown>,
    stage: ProcessingStage
  ): number {
    // å¦‚æœçµæœåŒ…å« confidence æ¬„ä½ï¼Œä½¿ç”¨å®ƒ
    if (typeof result.confidence === 'number') {
      return result.confidence;
    }

    // åŸºæ–¼éšæ®µå’Œçµæœå®Œæ•´åº¦è¨ˆç®—
    const baseConfidence = 0.7;
    const fields = Object.keys(result).filter(k => k !== 'raw' && k !== 'parseError');

    // æ¬„ä½æ•¸é‡å½±éŸ¿ä¿¡å¿ƒåº¦
    const fieldBonus = Math.min(fields.length * 0.03, 0.2);

    // è§£æéŒ¯èª¤é™ä½ä¿¡å¿ƒåº¦
    const parseErrorPenalty = result.parseError ? 0.3 : 0;

    return Math.max(0.1, Math.min(1, baseConfidence + fieldBonus - parseErrorPenalty));
  }

  /**
   * è¨ˆç®—æ•´é«”ä¿¡å¿ƒåº¦
   */
  private calculateOverallConfidence(stages: VisionResponse[]): number {
    if (stages.length === 0) return 0;

    const weights: Record<ProcessingStage, number> = {
      [ProcessingStage.ISSUER_IDENTIFICATION]: 0.2,
      [ProcessingStage.FIELD_EXTRACTION]: 0.4,
      [ProcessingStage.TERM_CLASSIFICATION]: 0.2,
      [ProcessingStage.VALIDATION]: 0.2,
    };

    let weightedSum = 0;
    let totalWeight = 0;

    for (const stage of stages) {
      const weight = weights[stage.stage];
      weightedSum += stage.confidence * weight;
      totalWeight += weight;
    }

    return totalWeight > 0 ? weightedSum / totalWeight : 0;
  }

  /**
   * ç²å– Prompt ä½¿ç”¨çµ±è¨ˆ
   */
  getPromptUsageStatistics() {
    return this.promptIntegration.getUsageStatistics();
  }
}
```

### æ¨¡çµ„å°å‡º

```typescript
// src/services/gpt-vision/index.ts

export * from './types';
export * from './prompt-integration.service';
export * from './gpt-vision.service';
```

---

## ğŸ”— API Endpoints

### Prompt ä½¿ç”¨çµ±è¨ˆ API

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/v1/admin/prompt-usage/statistics` | Prompt ä½¿ç”¨çµ±è¨ˆ |
| GET | `/api/v1/admin/prompt-usage/by-stage` | æŒ‰éšæ®µçµ±è¨ˆ |
| GET | `/api/v1/admin/prompt-usage/effectiveness` | æ•ˆæœåˆ†æ |

```typescript
// src/app/api/v1/admin/prompt-usage/statistics/route.ts

import { NextRequest, NextResponse } from 'next/server';
import { GPTVisionService } from '@/services/gpt-vision';

export async function GET(request: NextRequest) {
  try {
    const visionService = new GPTVisionService();
    const statistics = visionService.getPromptUsageStatistics();

    return NextResponse.json({
      success: true,
      data: statistics,
    });
  } catch (error) {
    return NextResponse.json(
      { success: false, error: 'Failed to get statistics' },
      { status: 500 }
    );
  }
}
```

---

## ğŸ§ª Testing Strategy

### å–®å…ƒæ¸¬è©¦

```typescript
// tests/unit/services/gpt-vision/prompt-integration.test.ts

import { PromptIntegrationService } from '@/services/gpt-vision';
import { ProcessingStage } from '@/services/gpt-vision/types';

describe('PromptIntegrationService', () => {
  let service: PromptIntegrationService;

  beforeEach(() => {
    service = new PromptIntegrationService();
  });

  describe('getPromptForStage', () => {
    it('should return prompt for issuer identification', async () => {
      const result = await service.getPromptForStage(
        ProcessingStage.ISSUER_IDENTIFICATION,
        { fileId: 'test-file' }
      );

      expect(result.prompt).toBeTruthy();
      expect(result.resolvedPrompt.promptType).toBe('ISSUER_IDENTIFICATION');
    });

    it('should include context variables', async () => {
      const result = await service.getPromptForStage(
        ProcessingStage.FIELD_EXTRACTION,
        {
          fileId: 'test-file',
          companyName: 'Test Company',
          formatName: 'Invoice Format A',
        }
      );

      expect(result.resolvedPrompt.variables).toHaveProperty('companyName');
    });
  });

  describe('getUsageStatistics', () => {
    it('should return empty statistics initially', () => {
      const stats = service.getUsageStatistics();
      expect(stats.totalCalls).toBe(0);
    });
  });
});
```

### æ•´åˆæ¸¬è©¦

```typescript
// tests/integration/services/gpt-vision/gpt-vision.test.ts

import { GPTVisionService } from '@/services/gpt-vision';
import { ProcessingStage } from '@/services/gpt-vision/types';

describe('GPTVisionService Integration', () => {
  let service: GPTVisionService;

  beforeEach(() => {
    service = new GPTVisionService();
  });

  describe('processStage', () => {
    it('should process with dynamic prompt', async () => {
      const mockImageBase64 = 'base64-encoded-image';

      const result = await service.processStage({
        imageBase64: mockImageBase64,
        stage: ProcessingStage.ISSUER_IDENTIFICATION,
        context: {
          fileId: 'test-file',
          companyId: 'test-company',
        },
      });

      expect(result.stage).toBe(ProcessingStage.ISSUER_IDENTIFICATION);
      expect(result.promptUsed.promptType).toBe('ISSUER_IDENTIFICATION');
      expect(result.processingTimeMs).toBeGreaterThan(0);
    });
  });
});
```

---

## ğŸ“ Files to Create/Modify

### New Files
| File | Description |
|------|-------------|
| `src/services/gpt-vision/prompt-integration.service.ts` | Prompt æ•´åˆæœå‹™ |
| `src/app/api/v1/admin/prompt-usage/statistics/route.ts` | çµ±è¨ˆ API |

### Modified Files
| File | Change |
|------|--------|
| `src/services/gpt-vision/gpt-vision.service.ts` | æ•´åˆ PromptEngine |
| `src/services/gpt-vision/types.ts` | æ–°å¢é¡å‹å®šç¾© |
| `src/services/gpt-vision/index.ts` | æ›´æ–°å°å‡º |

---

## ğŸ”— Dependencies

### Upstream
- **Story 14-3**: Prompt è§£æèˆ‡åˆä½µæœå‹™ï¼ˆPromptEngineï¼‰
- **Epic 0 - Story 0-2**: GPT Vision åŸºç¤æœå‹™

### Downstream
- **Story 15-1**: çµ±ä¸€è™•ç†æµç¨‹ï¼ˆèª¿ç”¨ GPT Vision æœå‹™ï¼‰

---

## ğŸ“ Implementation Notes

### éšæ®µè™•ç†é †åº
1. ISSUER_IDENTIFICATION - è­˜åˆ¥ç™¼è¡Œè€…
2. FIELD_EXTRACTION - æå–æ¬„ä½
3. TERM_CLASSIFICATION - åˆ†é¡è¡“èª
4. VALIDATION - é©—è­‰çµæœ

### ä¸Šä¸‹æ–‡å‚³é
- æ¯å€‹éšæ®µçš„çµæœæœƒå‚³éçµ¦ä¸‹ä¸€å€‹éšæ®µ
- é€šé `previousResults` æä¾›ä¸Šä¸‹æ–‡
- è®Šæ•¸æœƒè‡ªå‹•æ³¨å…¥åˆ° Prompt

### æ•ˆèƒ½å„ªåŒ–
- Prompt è§£æä½¿ç”¨å¿«å–
- ç›®æ¨™è§£ææ™‚é–“ < 50ms
- æ‰¹æ¬¡ç²å–å¤šéšæ®µ Prompt

---

## âœ… Definition of Done

- [ ] æ‰€æœ‰ Acceptance Criteria é€šé
- [ ] Prompt æ•´åˆæœå‹™å¯¦ç¾
- [ ] GPT Vision æœå‹™ä¿®æ”¹å®Œæˆ
- [ ] å››å€‹è™•ç†éšæ®µæ•´åˆå‹•æ…‹ Prompt
- [ ] ä½¿ç”¨çµ±è¨ˆ API å¯¦ç¾
- [ ] å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ > 80%
- [ ] æ•´åˆæ¸¬è©¦é€šé
- [ ] æ•ˆèƒ½æŒ‡æ¨™é”æ¨™ï¼ˆè§£æ < 50msï¼‰
- [ ] ç¨‹å¼ç¢¼å¯©æŸ¥é€šé

---

*Created: 2026-01-02*
*Epic: 14 - Prompt é…ç½®èˆ‡å‹•æ…‹ç”Ÿæˆ*
